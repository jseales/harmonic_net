# -*- coding: utf-8 -*-
"""Harmonic net

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ksNsmgEBy_0m4TRzIOxnmarZ1vd2oTG2
"""

import torch
import numpy as np
import torch.nn as nn
from torch.nn import functional as F

class SparseConv2D(nn.Module):

  def __init__(self, frames, indices):
    super(SparseConv2D, self).__init__()
    self.sparse_kernel_indices = indices 
    self.sparse_kernel_values = torch.randn(frames, indices.shape[0])
   
  def unfold_sparse_2D(self, input_tensor, indices):
    ''' indices should come in the form of a list of coordinate pairs. '''
    
    # Find the amount of zero padding needed to make the output the same
    # size as the input.
    left_pad = max(0, 0-np.min(indices[:,0]))
    top_pad = max(0, 0-np.min(indices[:,1]))
    right_pad = max(0, np.max(indices[:,0]))
    bottom_pad = max(0, np.max(indices[:,1]))
  
    input_array = input_tensor.numpy()
    padded_array = np.hstack((input_array, np.zeros((input_array.shape[0], right_pad + left_pad))))
    padded_array = np. vstack((padded_array, np.zeros((bottom_pad + top_pad, padded_array.shape[1]))))
  
    
    # Construct an array of indices for fancy indexing that slides 
    # along the input array.
    axis0_coords =  np.arange(input_array.shape[0], dtype=int) [:, np.newaxis] * np.ones(input_array.shape[1], dtype=int)
    axis1_coords =  np.ones(input_array.shape[0], dtype=int)[:, np.newaxis] * np.arange(input_array.shape[1], dtype=int)[np.newaxis, :] 
    
    axis0_ix = (axis0_coords[np.newaxis, :, :] + indices[:,1][:,np.newaxis,np.newaxis])
    axis1_ix = (axis1_coords[np.newaxis, :, :] + indices[:,0][:,np.newaxis,np.newaxis])
    return torch.tensor(padded_array[axis0_ix, axis1_ix], dtype=torch.float32)

  def forward(self, input_array):
    unfolded = torch.tensor(self.unfold_sparse_2D(input_array, self.sparse_kernel_indices), dtype = torch.float32)
    orig_shape = unfolded.shape
    linear_unfolded = unfolded.reshape(orig_shape[0], orig_shape[1] * orig_shape [2])
    linear_out = torch.mm(self.sparse_kernel_values, linear_unfolded)
    return linear_out.reshape(self.sparse_kernel_values.shape[0], orig_shape[1], orig_shape[2])

class HarmonicNet(nn.Module):
  def __init__():
    super(HarmonicNet, self).__init__()
    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1, padding_mode='zeros')
    self.bn1 = nn.BatchNorm2d(32)
    self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1, padding_mode='zeros')
    self.bn2 = nn.BatchNorm2d(32)
    self.do1 = nn.Dropout(p=0.2)
    self.conv3 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1, padding_mode='zeros')
    self.bn3 = nn.BatchNorm2d(32)
    self.do2 = nn.Dropout(p=0.2)
    self.sparseConv = SparseConv2D(256, sparse_kernel)
    self.bn4 = nn.BatchNorm2d(256)
    self.mp = nn.MaxPool2d(kernel_size=(3,1), stride=(3,1), padding = (1,0))
    self.do3 = nn.Dropout(p=0.2)
    self.fc1 = nn.Linear(264 * 256, 88 * 256)
    self.bn5 = nn.BatchNorm1d(1)
    self.do4 = nn.Dropout(p=0.2)
    self.fc2 = nn.Linear(88 * 256, 88)
    self.bn6 = nn.BatchNorm1d(1)
    self.do5 = nn.Dropout(p=0.2)
    self.lstm = nn.LSTM(input_size=88, hidden_size=88, num_layers=3, dropout=0.2)


  def forward(self, x):
    x = self.conv1(x)
    x = F.ReLu(x)
    x = self.bn1(x)
    x = self.conv2(x)
    x = F.ReLu(x)
    x = self.bn2(x)
    x = self.do1(x)
    x = self.conv3(x)
    x = F.ReLu(x)
    x = self.bn3(x)
    x = self.do2(x)
    x = self.sparseConv(x)
    x = F.ReLu(x)
    x = self.bn4(x)
    x = self.mp(x)
    x = self.do3(x)
    x = x.reshape(264 * 256)
    x = self.fc1(x)
    x = F.ReLU()
    x = self.bn5(x)
    x = self.do4(x)
    x = self.fc2(x)
    x = F.ReLu(x)
    x = self.bn6(x)
    x = self.do5(x)
    x = self.lstm(x)
    x = nn.sigmoid(x)



